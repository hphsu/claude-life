# å‘½ç†åˆ†æç³»çµ±å¢å¼·æŒ‡å—
## Fortune-Telling System Enhancement Guide

æœ¬æŒ‡å—åŸºæ–¼å°ˆæ¥­AIå‘½ç†ç³»çµ±çš„æœ€ä½³å¯¦è¸ï¼Œæä¾›ç³»çµ±æ€§çš„å‡ç´šæ–¹æ¡ˆã€‚

---

## ğŸ“Š ç ”ç©¶ç™¼ç¾ç¸½çµ

### å°ˆæ¥­ç³»çµ±çš„æ ¸å¿ƒç‰¹é»

#### 1. **å…§å®¹æ·±åº¦è¦æ±‚**
- âœ… æ¯å€‹åˆ†æç¶­åº¦ â‰¥300å­—
- âœ… é¿å…ç°¡çŸ­ã€ç± çµ±çš„æè¿°
- âœ… æä¾›å…·é«”ã€å¯æ“ä½œçš„å»ºè­°

#### 2. **æ¨™æº–åŒ–åˆ†ææ¶æ§‹**
```
åŸºç¤å‘½ç›¤ â†’ äº”å¤§é ˜åŸŸæ·±åº¦åˆ†æ â†’ æ™‚é–“è»¸é æ¸¬ â†’ ç¶œåˆå»ºè­°
```

#### 3. **ä¸‰æ–¹æ³•æ•´åˆé©—è­‰**
- ğŸ” æ‰¾å‡ºå…±åŒæŒ‡å‘çš„ç‰¹è³ªï¼ˆä¿¡å¿ƒåº¦æœ€é«˜ï¼‰
- ğŸ”„ ç”¨ä¸€ç¨®æ–¹æ³•è£œå……å¦ä¸€ç¨®çš„ç›²é»
- âš¡ äº¤å‰é©—è­‰é‡è¦çµè«–

---

## ğŸ¯ å¢å¼·æ–¹æ¡ˆ

### Phase 1: ç³»çµ±æç¤ºè©é›†æˆ â­â­â­â­â­

#### ç›®æ¨™
ç‚ºæ¯å€‹è§£é‡‹å¼•æ“æ·»åŠ å°ˆæ¥­ç´šç³»çµ±æç¤ºè©ï¼Œæå‡åˆ†æè³ªé‡ã€‚

#### å¯¦æ–½æ­¥é©Ÿ

**Step 1: ä¿®æ”¹ `bazi_interpretation.py`**

```python
# åœ¨æ–‡ä»¶é–‹é ­æ·»åŠ 
from pathlib import Path

def load_system_prompt():
    """åŠ è¼‰å…«å­—åˆ†æç³»çµ±æç¤ºè©"""
    prompt_file = Path(__file__).parent / 'prompts' / 'bazi_system_prompt.md'
    if prompt_file.exists():
        with open(prompt_file, 'r', encoding='utf-8') as f:
            return f.read()
    return None

# åœ¨æ¯å€‹interpretationå‡½æ•¸ä¸­ä½¿ç”¨
def interpret_personality(bazi_data: Dict) -> str:
    """
    å…«å­—æ€§æ ¼è§£é‡‹ï¼ˆå¢å¼·ç‰ˆï¼‰

    å¢å¼·å…§å®¹ï¼š
    1. éµå¾ªç³»çµ±æç¤ºè©çš„å°ˆæ¥­æ¨™æº–
    2. è¼¸å‡ºâ‰¥300å­—çš„æ·±åº¦åˆ†æ
    3. åŒ…å«å…·é«”çš„è¡Œç‚ºæ¨¡å¼å’Œå¿ƒç†ç‰¹é»
    """
    system_prompt = load_system_prompt()

    # æ§‹å»ºåˆ†ææç¤º
    analysis_prompt = f"""
{system_prompt}

è«‹æ ¹æ“šä»¥ä¸‹å…«å­—å‘½ç›¤æ•¸æ“šï¼Œé€²è¡Œæ·±åº¦çš„æ€§æ ¼åˆ†æï¼ˆâ‰¥300å­—ï¼‰ï¼š

å››æŸ±è³‡æ–™ï¼š
{json.dumps(bazi_data, ensure_ascii=False, indent=2)}

è«‹æŒ‰ç…§ç³»çµ±æç¤ºè©ä¸­ã€Œæ€§æ ¼ç‰¹è³ªã€çš„åˆ†ææ¡†æ¶ï¼Œæä¾›ï¼š
1. æ—¥ä¸»ç‰¹æ€§åˆ†æ
2. åç¥é…ç½®è§£è®€
3. ç¥ç…å½±éŸ¿
4. äº”è¡Œåé —çš„å¿ƒç†å½±éŸ¿
5. å…·é«”çš„è¡Œç‚ºæ¨¡å¼å’Œå»ºè­°

è¼¸å‡ºæ ¼å¼ï¼šå°ˆæ¥­çš„Markdownæ ¼å¼ï¼Œæ¸…æ™°åˆ†å±¤ã€‚
"""

    # é€™è£¡å¯ä»¥èª¿ç”¨LLM APIé€²è¡Œåˆ†æ
    # æˆ–è€…ä¿æŒç¾æœ‰é‚è¼¯ä½†å¢å¼·è¼¸å‡ºè³ªé‡

    return enhanced_analysis
```

**Step 2: ä¿®æ”¹ `ziwei_interpretation.py`**

```python
def load_ziwei_system_prompt():
    """åŠ è¼‰ç´«å¾®æ–—æ•¸åˆ†æç³»çµ±æç¤ºè©"""
    prompt_file = Path(__file__).parent / 'prompts' / 'ziwei_system_prompt.md'
    if prompt_file.exists():
        with open(prompt_file, 'r', encoding='utf-8') as f:
            return f.read()
    return None

def interpret_ziwei_palaces(ziwei_data: Dict) -> Dict:
    """
    ç´«å¾®æ–—æ•¸å®®ä½è§£é‡‹ï¼ˆå¢å¼·ç‰ˆï¼‰

    å¢å¼·å…§å®¹ï¼š
    1. æ¯å€‹é‡é»å®®ä½â‰¥250å­—
    2. æ¬¡è¦å®®ä½â‰¥150å­—
    3. åŒ…å«æ˜Ÿæ›œäº’å‹•åˆ†æ
    4. æ¨™è¨»ä¿¡å¿ƒåº¦
    """
    system_prompt = load_ziwei_system_prompt()

    palace_analyses = {}

    # é‡é»å®®ä½ï¼ˆå‘½ã€å®˜ã€è²¡ã€å¤«ã€ç¦ï¼‰
    for palace_name in ['å‘½å®®', 'å®˜ç¥¿å®®', 'è²¡å¸›å®®', 'å¤«å¦»å®®', 'ç¦å¾·å®®']:
        palace_data = ziwei_data['palaces'].get(palace_name, {})

        analysis_prompt = f"""
{system_prompt}

è«‹æ·±åº¦åˆ†æã€{palace_name}ã€‘ï¼ˆâ‰¥250å­—ï¼‰ï¼š

å®®ä½è³‡æ–™ï¼š
{json.dumps(palace_data, ensure_ascii=False, indent=2)}

è«‹æŒ‰ç…§ç³»çµ±æç¤ºè©ä¸­çš„åˆ†ææ¡†æ¶æä¾›ï¼š
1. ä¸»æ˜Ÿç‰¹è³ªè©³è§£
2. è¼”ç…å½±éŸ¿åˆ†æ
3. å››åŒ–æ•ˆæ‡‰è§£è®€
4. ä¸‰æ–¹å››æ­£ç¶œåˆ
5. å…·é«”å»ºè­°å’Œä¿¡å¿ƒåº¦
"""

        palace_analyses[palace_name] = enhanced_palace_analysis

    return {
        'palace_interpretations': palace_analyses,
        'overall_confidence': calculate_confidence(palace_analyses)
    }
```

**Step 3: ä¿®æ”¹ `astrology_interpretation.py`**

```python
def load_astrology_system_prompt():
    """åŠ è¼‰å¿ƒç†å æ˜Ÿåˆ†æç³»çµ±æç¤ºè©"""
    prompt_file = Path(__file__).parent / 'prompts' / 'astrology_system_prompt.md'
    if prompt_file.exists():
        with open(prompt_file, 'r', encoding='utf-8') as f:
            return f.read()
    return None

def interpret_natal_chart(astrology_data: Dict) -> Dict:
    """
    æœ¬å‘½ç›¤å¿ƒç†å æ˜Ÿè§£é‡‹ï¼ˆå¢å¼·ç‰ˆï¼‰

    å¢å¼·å…§å®¹ï¼š
    1. æ¯å€‹æ ¸å¿ƒé ˜åŸŸâ‰¥300å­—
    2. å¿ƒç†å­¸æ•´åˆåˆ†æ
    3. è³¦èƒ½å¼èªè¨€
    4. æˆé•·å°å‘å»ºè­°
    """
    system_prompt = load_astrology_system_prompt()

    # æ ¸å¿ƒé…ç½®åˆ†æ
    core_analyses = {}

    core_areas = {
        'solar_identity': 'æ ¸å¿ƒè‡ªæˆ‘',
        'lunar_landscape': 'æƒ…æ„Ÿä¸–ç•Œ',
        'ascendant_persona': 'äººæ ¼é¢å…·',
        'mercurial_mind': 'å¿ƒæ™ºæºé€š',
        'venusian_values': 'æ„›èˆ‡åƒ¹å€¼',
        'martial_drive': 'æ…¾æœ›è¡Œå‹•'
    }

    for area_key, area_name in core_areas.items():
        analysis_prompt = f"""
{system_prompt}

è«‹é€²è¡Œã€{area_name}ã€‘çš„å¿ƒç†å æ˜Ÿæ·±åº¦åˆ†æï¼ˆâ‰¥300å­—ï¼‰ï¼š

æ˜Ÿç›¤è³‡æ–™ï¼š
{json.dumps(astrology_data, ensure_ascii=False, indent=2)}

è«‹æŒ‰ç…§ç³»çµ±æç¤ºè©æä¾›ï¼š
1. è¡Œæ˜Ÿ/ä¸Šå‡é»çš„æ˜Ÿåº§ç‰¹è³ª
2. å®®ä½ä½ç½®çš„æ„ç¾©
3. ä¸»è¦ç›¸ä½çš„å¿ƒç†å‹•åŠ›
4. ç™¼å±•èª²é¡Œå’Œæˆé•·æ–¹å‘
5. æ•´åˆå»ºè­°ï¼ˆä½¿ç”¨è³¦èƒ½å¼èªè¨€ï¼‰
"""

        core_analyses[area_key] = enhanced_psychological_analysis

    return {
        'psychological_profile': core_analyses,
        'growth_directions': extract_growth_directions(core_analyses),
        'confidence_levels': calculate_confidence(core_analyses)
    }
```

**Step 4: å¢å¼· `synthesis_engine.py`**

```python
def load_synthesis_system_prompt():
    """åŠ è¼‰ä¸‰æ–¹æ³•ç¶œåˆåˆ†æç³»çµ±æç¤ºè©"""
    prompt_file = Path(__file__).parent / 'prompts' / 'synthesis_system_prompt.md'
    if prompt_file.exists():
        with open(prompt_file, 'r', encoding='utf-8') as f:
            return f.read()
    return None

def synthesize_three_methods(
    bazi_result: Dict,
    ziwei_result: Dict,
    astro_result: Dict
) -> Dict:
    """
    ä¸‰æ–¹æ³•ç¶œåˆåˆ†æï¼ˆå¢å¼·ç‰ˆï¼‰

    å¢å¼·å…§å®¹ï¼š
    1. è­˜åˆ¥å…±æŒ¯é»ï¼ˆä¸‰æ–¹ä¸€è‡´ï¼‰
    2. äº’è£œç›²é»ï¼ˆç›¸äº’è£œå……ï¼‰
    3. è™•ç†çŸ›ç›¾ï¼ˆèª å¯¦èªªæ˜ï¼‰
    4. ä¿¡å¿ƒåº¦è©•ä¼°ï¼ˆé‡åŒ–å¯é åº¦ï¼‰
    5. æ¯å€‹é ˜åŸŸâ‰¥400å­—ç¶œåˆåˆ†æ
    """
    system_prompt = load_synthesis_system_prompt()

    synthesis_results = {}

    # äº”å¤§é ˜åŸŸç¶œåˆ
    domains = {
        'personality': 'æ ¸å¿ƒäººæ ¼',
        'career': 'äº‹æ¥­ç™¼å±•',
        'wealth': 'è²¡å¯Œé‹å‹¢',
        'relationship': 'æ„Ÿæƒ…å©šå§»',
        'health': 'å¥åº·ç‹€æ³'
    }

    for domain_key, domain_name in domains.items():
        # æå–ä¸‰æ–¹æ•¸æ“š
        bazi_data = bazi_result.get(domain_key, {})
        ziwei_data = ziwei_result.get(domain_key, {})
        astro_data = astro_result.get(domain_key, {})

        synthesis_prompt = f"""
{system_prompt}

è«‹é€²è¡Œã€{domain_name}ã€‘çš„ä¸‰æ–¹æ³•ç¶œåˆåˆ†æï¼ˆâ‰¥400å­—ï¼‰ï¼š

å…«å­—æ•¸æ“šï¼š
{json.dumps(bazi_data, ensure_ascii=False, indent=2)}

ç´«å¾®æ•¸æ“šï¼š
{json.dumps(ziwei_data, ensure_ascii=False, indent=2)}

å æ˜Ÿæ•¸æ“šï¼š
{json.dumps(astro_data, ensure_ascii=False, indent=2)}

è«‹æŒ‰ç…§ç³»çµ±æç¤ºè©æä¾›ï¼š
1. è­˜åˆ¥å…±æŒ¯é»ï¼ˆä¸‰æ–¹ä¸€è‡´çš„ç‰¹è³ªï¼‰
2. è·¨æ–¹æ³•æ•´åˆæ´å¯Ÿ
3. ä¿¡å¿ƒåº¦è©•ä¼°ï¼ˆæ¥µé«˜/é«˜/ä¸­ç­‰ï¼‰
4. æ•´åˆå»ºè­°
5. éœ€è¦æ³¨æ„çš„çŸ›ç›¾é»ï¼ˆå¦‚æœ‰ï¼‰

è¼¸å‡ºæ ¼å¼ï¼šæŒ‰ç…§ç³»çµ±æç¤ºè©ä¸­çš„Markdownæ¨¡æ¿ã€‚
"""

        synthesis_results[f'{domain_key}_synthesis'] = {
            'narrative': enhanced_synthesis_analysis,
            'overall_rating': calculate_rating(bazi_data, ziwei_data, astro_data),
            'confidence': calculate_confidence_level(bazi_data, ziwei_data, astro_data),
            'consistency': calculate_consistency(bazi_data, ziwei_data, astro_data)
        }

    return synthesis_results
```

---

### Phase 2: å…§å®¹è³ªé‡æå‡ â­â­â­â­

#### å¢å¼·é»

**1. æœ€ä½å­—æ•¸è¦æ±‚**
```python
def validate_analysis_length(analysis_text: str, min_chars: int = 300) -> bool:
    """é©—è­‰åˆ†æå…§å®¹æ˜¯å¦é”åˆ°æœ€ä½å­—æ•¸è¦æ±‚"""
    actual_length = len(analysis_text.replace(' ', '').replace('\n', ''))
    if actual_length < min_chars:
        logger.warning(f"åˆ†æå…§å®¹åƒ…{actual_length}å­—ï¼Œæœªé”{min_chars}å­—æ¨™æº–")
        return False
    return True
```

**2. çµæ§‹åŒ–è¼¸å‡ºæ¨¡æ¿**
```python
PERSONALITY_TEMPLATE = """
## æ€§æ ¼ç‰¹è³ªæ·±åº¦åˆ†æ

### æ—¥ä¸»ç‰¹æ€§
{day_master_analysis}

### åç¥é…ç½®
{ten_gods_analysis}

### ç¥ç…å½±éŸ¿
{deities_analysis}

### äº”è¡Œåé —å½±éŸ¿
{elements_imbalance}

### å…·é«”è¡Œç‚ºæ¨¡å¼
{behavior_patterns}

### æ€§æ ¼æ”¹å–„å»ºè­°
{improvement_suggestions}

**ä¿¡å¿ƒåº¦**: {confidence_level}
**åˆ†æä¾æ“š**: {analysis_basis}
"""
```

**3. ä¿¡å¿ƒåº¦è©•ä¼°ç³»çµ±**
```python
def calculate_confidence_level(
    consensus_indicators: int,
    data_quality: float,
    theoretical_support: float
) -> Dict:
    """
    è¨ˆç®—åˆ†æçµè«–çš„ä¿¡å¿ƒåº¦

    Args:
        consensus_indicators: ä¸‰æ–¹ä¸€è‡´æŒ‡æ¨™æ•¸é‡
        data_quality: æ•¸æ“šè³ªé‡ (0-1)
        theoretical_support: ç†è«–æ”¯æŒåº¦ (0-1)

    Returns:
        ä¿¡å¿ƒåº¦è©•ä¼°çµæœ
    """
    confidence_score = (
        (consensus_indicators / 3) * 0.5 +  # ä¸€è‡´æ€§æ¬Šé‡50%
        data_quality * 0.3 +                 # æ•¸æ“šè³ªé‡30%
        theoretical_support * 0.2            # ç†è«–æ”¯æŒ20%
    )

    if confidence_score >= 0.95:
        level = "æ¥µé«˜"
        description = "ä¸‰æ–¹æ³•éƒ½æ˜ç¢ºæŒ‡å‘åŒä¸€çµè«–"
    elif confidence_score >= 0.80:
        level = "é«˜"
        description = "å…©æ–¹æ³•æ˜ç¢ºä¸€è‡´ï¼Œç¬¬ä¸‰æ–¹ä¸çŸ›ç›¾"
    elif confidence_score >= 0.60:
        level = "ä¸­ç­‰"
        description = "å…©æ–¹æ³•ä¸€è‡´ï¼Œç¬¬ä¸‰æ–¹æœ‰å·®ç•°"
    else:
        level = "è¼ƒä½"
        description = "ä¸‰æ–¹æ³•å„æœ‰å´é‡ï¼Œéœ€ç¶œåˆç†è§£"

    return {
        'score': confidence_score,
        'level': level,
        'description': description
    }
```

---

### Phase 3: LLM APIé›†æˆ â­â­â­â­â­

#### ç›®æ¨™
ä½¿ç”¨AIå¤§èªè¨€æ¨¡å‹ç”Ÿæˆå°ˆæ¥­ã€æ·±å…¥çš„åˆ†æå…§å®¹ã€‚

#### æ¨è–¦æ–¹æ¡ˆ

**Option 1: OpenAI API (GPT-4)**
```python
import openai
from typing import Dict

class LLMAnalyzer:
    """LLMè¼”åŠ©åˆ†æå™¨"""

    def __init__(self, api_key: str, model: str = "gpt-4"):
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model

    def analyze_with_prompt(
        self,
        system_prompt: str,
        analysis_prompt: str,
        temperature: float = 0.7
    ) -> str:
        """ä½¿ç”¨LLMé€²è¡Œåˆ†æ"""
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": analysis_prompt}
            ],
            temperature=temperature,
            max_tokens=2000  # ç¢ºä¿æœ‰è¶³å¤ tokensè¼¸å‡ºæ·±åº¦åˆ†æ
        )

        return response.choices[0].message.content

    def analyze_bazi_personality(self, bazi_data: Dict) -> str:
        """å…«å­—æ€§æ ¼åˆ†æ"""
        system_prompt = load_system_prompt('bazi_system_prompt.md')

        analysis_prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹å…«å­—å‘½ç›¤æ•¸æ“šï¼Œé€²è¡Œæ·±åº¦çš„æ€§æ ¼åˆ†æï¼ˆâ‰¥300å­—ï¼‰ï¼š

{json.dumps(bazi_data, ensure_ascii=False, indent=2)}

è«‹åš´æ ¼æŒ‰ç…§ç³»çµ±æç¤ºè©ä¸­ã€Œæ€§æ ¼ç‰¹è³ªã€çš„åˆ†ææ¡†æ¶é€²è¡Œåˆ†æã€‚
"""

        return self.analyze_with_prompt(system_prompt, analysis_prompt)
```

**Option 2: Anthropic Claude API**
```python
import anthropic
from typing import Dict

class ClaudeAnalyzer:
    """Claudeè¼”åŠ©åˆ†æå™¨"""

    def __init__(self, api_key: str, model: str = "claude-3-opus-20240229"):
        self.client = anthropic.Anthropic(api_key=api_key)
        self.model = model

    def analyze_with_prompt(
        self,
        system_prompt: str,
        analysis_prompt: str,
        max_tokens: int = 4000
    ) -> str:
        """ä½¿ç”¨Claudeé€²è¡Œåˆ†æ"""
        message = self.client.messages.create(
            model=self.model,
            max_tokens=max_tokens,
            system=system_prompt,
            messages=[
                {"role": "user", "content": analysis_prompt}
            ]
        )

        return message.content[0].text
```

**é›†æˆåˆ°è§£é‡‹å¼•æ“**
```python
# åœ¨ bazi_interpretation.py ä¸­

def interpret_personality(bazi_data: Dict, use_llm: bool = True) -> str:
    """å…«å­—æ€§æ ¼è§£é‡‹ï¼ˆæ”¯æŒLLMå¢å¼·ï¼‰"""

    if use_llm and os.getenv('OPENAI_API_KEY'):
        # ä½¿ç”¨LLMç”Ÿæˆæ·±åº¦åˆ†æ
        analyzer = LLMAnalyzer(api_key=os.getenv('OPENAI_API_KEY'))
        system_prompt = load_system_prompt()

        analysis_prompt = construct_bazi_personality_prompt(bazi_data)
        enhanced_analysis = analyzer.analyze_with_prompt(
            system_prompt,
            analysis_prompt
        )

        # é©—è­‰è¼¸å‡ºè³ªé‡
        if validate_analysis_length(enhanced_analysis, min_chars=300):
            return enhanced_analysis
        else:
            logger.warning("LLMè¼¸å‡ºæœªé”æ¨™æº–ï¼Œä½¿ç”¨å‚³çµ±æ–¹æ³•")

    # Fallbackï¼šä½¿ç”¨å‚³çµ±è¦å‰‡å¼•æ“
    return traditional_personality_analysis(bazi_data)
```

---

### Phase 4: HTMLå ±å‘Šå¢å¼· â­â­â­

#### å¢å¼·å…§å®¹

**1. æ·»åŠ ä¿¡å¿ƒåº¦è¦–è¦ºåŒ–**
```html
<!-- åœ¨ html_report_generator.py ä¸­ -->

<div class="confidence-indicator">
    <div class="confidence-label">åˆ†æä¿¡å¿ƒåº¦</div>
    <div class="confidence-bar">
        <div class="confidence-fill" style="width: {confidence}%"></div>
    </div>
    <div class="confidence-text">{confidence_level} ({confidence}%)</div>
</div>

<style>
.confidence-bar {
    width: 100%;
    height: 20px;
    background: #e0e0e0;
    border-radius: 10px;
    overflow: hidden;
}

.confidence-fill {
    height: 100%;
    background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    transition: width 0.3s ease;
}
</style>
```

**2. æ·»åŠ ä¸‰æ–¹æ³•å°æ¯”è¦–åœ–**
```html
<div class="three-methods-comparison">
    <h3>ğŸ” ä¸‰æ–¹æ³•è¦–è§’å°æ¯”</h3>
    <table class="comparison-table">
        <tr>
            <th>åˆ†æç¶­åº¦</th>
            <th>å…«å­—</th>
            <th>ç´«å¾®</th>
            <th>å æ˜Ÿ</th>
            <th>ä¸€è‡´æ€§</th>
        </tr>
        <tr>
            <td>æ€§æ ¼ç‰¹è³ª</td>
            <td>{bazi_personality}</td>
            <td>{ziwei_personality}</td>
            <td>{astro_personality}</td>
            <td><span class="consistency-badge high">æ¥µé«˜</span></td>
        </tr>
        <!-- æ›´å¤šè¡Œ -->
    </table>
</div>
```

**3. æ·»åŠ æ™‚é–“è»¸å¯è¦–åŒ–**
```html
<div class="timeline-visualization">
    <h3>ğŸ“… äººç”Ÿé‹å‹¢æ™‚é–“è»¸</h3>
    <div class="timeline">
        <div class="timeline-item" data-age="20-30">
            <div class="timeline-marker"></div>
            <div class="timeline-content">
                <h4>20-30æ­²ï¼šå­¸ç¿’ç´¯ç©æœŸ</h4>
                <p>ä¸‰æ–¹ä¸€è‡´ï¼šé‡é»åœ¨å°ˆæ¥­èƒ½åŠ›åŸ¹é¤Š</p>
            </div>
        </div>
        <!-- æ›´å¤šæ™‚é–“ç¯€é» -->
    </div>
</div>
```

---

## ğŸš€ å¯¦æ–½å„ªå…ˆç´š

### ğŸ”¥ High Priority (ç«‹å³å¯¦æ–½)
1. **Phase 1**: ç³»çµ±æç¤ºè©é›†æˆ - æœ€å¿«è¦‹æ•ˆ
2. **Phase 2**: å…§å®¹è³ªé‡æå‡ - ç”¨æˆ¶é«”é©—é—œéµ

### ğŸŒŸ Medium Priority (çŸ­æœŸè¨ˆåŠƒ)
3. **Phase 3**: LLM APIé›†æˆ - è³ªçš„é£›èº
4. **Phase 4**: HTMLå ±å‘Šå¢å¼· - è¦–è¦ºé«”é©—

---

## ğŸ“ å¯¦æ–½æª¢æŸ¥æ¸…å–®

### Phase 1 æª¢æŸ¥
- [ ] å‰µå»º prompts ç›®éŒ„
- [ ] æ”¾ç½®4å€‹ç³»çµ±æç¤ºè©æ–‡ä»¶
- [ ] ä¿®æ”¹ bazi_interpretation.py
- [ ] ä¿®æ”¹ ziwei_interpretation.py
- [ ] ä¿®æ”¹ astrology_interpretation.py
- [ ] ä¿®æ”¹ synthesis_engine.py
- [ ] æ¸¬è©¦å®Œæ•´åˆ†ææµç¨‹

### Phase 2 æª¢æŸ¥
- [ ] å¯¦ç¾å­—æ•¸é©—è­‰å‡½æ•¸
- [ ] å‰µå»ºçµæ§‹åŒ–æ¨¡æ¿
- [ ] å¯¦ç¾ä¿¡å¿ƒåº¦è¨ˆç®—
- [ ] åœ¨å„è§£é‡‹å¼•æ“ä¸­æ‡‰ç”¨
- [ ] æ›´æ–°HTMLç”Ÿæˆå™¨é¡¯ç¤ºä¿¡å¿ƒåº¦

### Phase 3 æª¢æŸ¥
- [ ] é¸æ“‡LLMæœå‹™å•†
- [ ] å¯¦ç¾LLM Analyzeré¡
- [ ] é›†æˆåˆ°å„è§£é‡‹å¼•æ“
- [ ] å¯¦ç¾fallbackæ©Ÿåˆ¶
- [ ] æ€§èƒ½å’Œæˆæœ¬æ¸¬è©¦

### Phase 4 æª¢æŸ¥
- [ ] æ·»åŠ ä¿¡å¿ƒåº¦è¦–è¦ºåŒ–
- [ ] å¯¦ç¾ä¸‰æ–¹æ³•å°æ¯”è¦–åœ–
- [ ] æ·»åŠ æ™‚é–“è»¸å¯è¦–åŒ–
- [ ] å„ªåŒ–ç§»å‹•ç«¯éŸ¿æ‡‰å¼
- [ ] æ·»åŠ æ‰“å°æ¨£å¼

---

## ğŸ’¡ é—œéµæ”¹é€²é»ç¸½çµ

### 1. **æ·±åº¦å„ªæ–¼å»£åº¦**
- âŒ èˆŠæ–¹å¼ï¼šæ¯å€‹é ˜åŸŸ100å­—ç°¡è¿°
- âœ… æ–°æ–¹å¼ï¼šæ¯å€‹é ˜åŸŸâ‰¥300å­—æ·±åº¦åˆ†æ

### 2. **å¯ä¿¡åº¦é€æ˜åŒ–**
- âŒ èˆŠæ–¹å¼ï¼šæ‰€æœ‰çµè«–çœ‹ä¼¼åŒç­‰é‡è¦
- âœ… æ–°æ–¹å¼ï¼šæ¨™è¨»æ¯å€‹çµè«–çš„ä¿¡å¿ƒåº¦

### 3. **ä¸‰æ–¹æ³•çœŸæ­£æ•´åˆ**
- âŒ èˆŠæ–¹å¼ï¼šä¸‰ç¨®æ–¹æ³•å„è‡ªç¨ç«‹
- âœ… æ–°æ–¹å¼ï¼šè­˜åˆ¥å…±é³´ã€äº’è£œç›²é»ã€è™•ç†çŸ›ç›¾

### 4. **å°ˆæ¥­åŒ–ç³»çµ±æç¤ºè©**
- âŒ èˆŠæ–¹å¼ï¼šç°¡å–®çš„åˆ†æé‚è¼¯
- âœ… æ–°æ–¹å¼ï¼šåŸºæ–¼å°ˆæ¥­å¤§å¸«ç¶“é©—çš„ç³»çµ±æç¤ºè©

### 5. **AIè³¦èƒ½**
- âŒ èˆŠæ–¹å¼ï¼šç´”è¦å‰‡å¼•æ“
- âœ… æ–°æ–¹å¼ï¼šè¦å‰‡å¼•æ“ + LLMæ·±åº¦åˆ†æ

---

## ğŸ“ å¾ŒçºŒæ”¯æŒ

å¦‚éœ€é€²ä¸€æ­¥å”åŠ©ï¼š
1. LLM APIé¸æ“‡å’Œé…ç½®
2. å…·é«”ä»£ç¢¼å¯¦ç¾
3. æ€§èƒ½å„ªåŒ–å»ºè­°
4. å¤šèªè¨€æ”¯æŒ
5. ç”¨æˆ¶ç•Œé¢è¨­è¨ˆ

è«‹éš¨æ™‚æå‡ºï¼ğŸš€
