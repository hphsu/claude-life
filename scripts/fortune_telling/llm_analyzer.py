"""
LLMåˆ†æå¼•æ“
LLM Analyzer for Fortune-Telling Deep Analysis

æ”¯æŒClaude Codeã€OpenAI GPT-4å’ŒAnthropic Claudeé€²è¡Œæ·±åº¦å‘½ç†åˆ†æ
"""

import os
import json
import logging
import subprocess
import shlex
from typing import Dict, Optional, Callable
from enum import Enum
from pathlib import Path

logger = logging.getLogger(__name__)


class LLMProvider(Enum):
    """LLMæœå‹™æä¾›å•†"""
    CLAUDE_CODE = "claude_code"  # Use Claude Code Task agents (no API key needed)
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    NONE = "none"


class LLMAnalyzer:
    """
    LLMè¼”åŠ©åˆ†æå™¨

    æ”¯æŒå¤šå€‹LLMæä¾›å•†ï¼Œè‡ªå‹•fallbackåˆ°è¦å‰‡å¼•æ“
    """

    def __init__(
        self,
        provider: LLMProvider = LLMProvider.OPENAI,
        api_key: Optional[str] = None,
        model: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–LLMåˆ†æå™¨

        Args:
            provider: LLMæä¾›å•†
            api_key: APIå¯†é‘°ï¼ˆå¦‚æœç‚ºNoneå‰‡å¾ç’°å¢ƒè®Šé‡è®€å–ï¼‰
            model: æ¨¡å‹åç¨±ï¼ˆå¦‚æœç‚ºNoneå‰‡ä½¿ç”¨é»˜èªæ¨¡å‹ï¼‰
        """
        self.provider = provider
        self.api_key = api_key or self._get_api_key_from_env()
        self.model = model or self._get_default_model()
        self.client = None

        # åˆå§‹åŒ–å®¢æˆ¶ç«¯
        if self.provider == LLMProvider.CLAUDE_CODE:
            # Claude Code doesn't need API key
            self.client = "claude_code_available"
            logger.info("Claude Codeæä¾›å•†åˆå§‹åŒ–æˆåŠŸ")
        elif self.api_key and provider != LLMProvider.NONE:
            self._initialize_client()

    def _get_api_key_from_env(self) -> Optional[str]:
        """å¾ç’°å¢ƒè®Šé‡ç²å–APIå¯†é‘°"""
        if self.provider == LLMProvider.CLAUDE_CODE:
            return "claude_code"  # No real API key needed
        elif self.provider == LLMProvider.OPENAI:
            return os.getenv('OPENAI_API_KEY')
        elif self.provider == LLMProvider.ANTHROPIC:
            return os.getenv('ANTHROPIC_API_KEY')
        return None

    def _get_default_model(self) -> str:
        """ç²å–é»˜èªæ¨¡å‹"""
        if self.provider == LLMProvider.OPENAI:
            return "gpt-4-turbo-preview"  # or "gpt-4"
        elif self.provider == LLMProvider.ANTHROPIC:
            return "claude-3-opus-20240229"  # or "claude-3-sonnet-20240229"
        return ""

    def _initialize_client(self):
        """åˆå§‹åŒ–LLMå®¢æˆ¶ç«¯"""
        try:
            if self.provider == LLMProvider.OPENAI:
                import openai
                self.client = openai.OpenAI(api_key=self.api_key)
                logger.info(f"OpenAIå®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.model}")

            elif self.provider == LLMProvider.ANTHROPIC:
                import anthropic
                self.client = anthropic.Anthropic(api_key=self.api_key)
                logger.info(f"Anthropicå®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.model}")

        except ImportError as e:
            logger.error(f"LLMåº«å°å…¥å¤±æ•—: {e}")
            logger.info("æç¤º: pip install openai anthropic")
            self.client = None
        except Exception as e:
            logger.error(f"LLMå®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—: {e}")
            self.client = None

    def is_available(self) -> bool:
        """æª¢æŸ¥LLMæ˜¯å¦å¯ç”¨"""
        return self.client is not None and self.api_key is not None

    def analyze_with_prompt(
        self,
        system_prompt: str,
        analysis_prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 4000
    ) -> Optional[str]:
        """
        ä½¿ç”¨LLMé€²è¡Œåˆ†æ

        Args:
            system_prompt: ç³»çµ±æç¤ºè©
            analysis_prompt: åˆ†ææç¤º
            temperature: æº«åº¦åƒæ•¸ï¼ˆ0-1ï¼‰
            max_tokens: æœ€å¤§tokenæ•¸

        Returns:
            åˆ†æçµæœï¼Œå¤±æ•—è¿”å›None
        """
        if not self.is_available():
            logger.warning("LLMä¸å¯ç”¨ï¼Œè·³éAIåˆ†æ")
            return None

        try:
            if self.provider == LLMProvider.CLAUDE_CODE:
                return self._analyze_with_claude_code(
                    system_prompt,
                    analysis_prompt,
                    max_tokens
                )
            elif self.provider == LLMProvider.OPENAI:
                return self._analyze_with_openai(
                    system_prompt,
                    analysis_prompt,
                    temperature,
                    max_tokens
                )
            elif self.provider == LLMProvider.ANTHROPIC:
                return self._analyze_with_anthropic(
                    system_prompt,
                    analysis_prompt,
                    max_tokens
                )
        except Exception as e:
            logger.error(f"LLMåˆ†æå¤±æ•—: {e}")
            return None

    def _analyze_with_openai(
        self,
        system_prompt: str,
        analysis_prompt: str,
        temperature: float,
        max_tokens: int
    ) -> Optional[str]:
        """ä½¿ç”¨OpenAIé€²è¡Œåˆ†æ"""
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": analysis_prompt}
            ],
            temperature=temperature,
            max_tokens=max_tokens
        )

        result = response.choices[0].message.content
        logger.info(f"OpenAIåˆ†æå®Œæˆï¼Œè¿”å›{len(result)}å­—")
        return result

    def _analyze_with_anthropic(
        self,
        system_prompt: str,
        analysis_prompt: str,
        max_tokens: int
    ) -> Optional[str]:
        """ä½¿ç”¨Anthropic Claudeé€²è¡Œåˆ†æ"""
        message = self.client.messages.create(
            model=self.model,
            max_tokens=max_tokens,
            system=system_prompt,
            messages=[
                {"role": "user", "content": analysis_prompt}
            ]
        )

        result = message.content[0].text
        logger.info(f"Claudeåˆ†æå®Œæˆï¼Œè¿”å›{len(result)}å­—")
        return result

    def _analyze_with_claude_code(
        self,
        system_prompt: str,
        analysis_prompt: str,
        max_tokens: int
    ) -> Optional[str]:
        """ä½¿ç”¨Claude Codeé€²è¡Œåˆ†æ

        æ³¨æ„ï¼šæ­¤æ–¹æ³•éœ€è¦é€šé /sc:implement ç­‰å‘½ä»¤æ‰‹å‹•èª¿ç”¨
        å› ç‚º Task tool ç„¡æ³•åœ¨ Python åŸ·è¡ŒæœŸé–“èª¿ç”¨ï¼ˆæœƒç”¢ç”Ÿéè¿´ï¼‰
        å»ºè­°ç›´æ¥ä½¿ç”¨ OPENAI æˆ– ANTHROPIC provider
        """
        logger.warning(
            "CLAUDE_CODE provider ç„¡æ³•åœ¨é‹è¡Œæ™‚è‡ªå‹•èª¿ç”¨ã€‚"
            "è«‹æ”¹ç”¨ OPENAI æˆ– ANTHROPIC providerï¼Œ"
            "æˆ–æ‰‹å‹•ä½¿ç”¨ /fortune-tell å‘½ä»¤èª¿ç”¨åˆ†æã€‚"
        )
        return None

    def analyze_with_fallback(
        self,
        system_prompt: str,
        analysis_prompt: str,
        fallback_func: Callable,
        fallback_args: tuple = (),
        min_length: int = 300,
        **llm_kwargs
    ) -> str:
        """
        ä½¿ç”¨LLMåˆ†æï¼Œå¤±æ•—å‰‡fallbackåˆ°å‚³çµ±æ–¹æ³•

        Args:
            system_prompt: ç³»çµ±æç¤ºè©
            analysis_prompt: åˆ†ææç¤º
            fallback_func: fallbackå‡½æ•¸
            fallback_args: fallbackå‡½æ•¸åƒæ•¸
            min_length: æœ€ä½å­—æ•¸è¦æ±‚
            **llm_kwargs: LLMé¡å¤–åƒæ•¸

        Returns:
            åˆ†æçµæœï¼ˆLLMæˆ–fallbackï¼‰
        """
        # å˜—è©¦ä½¿ç”¨LLM
        if self.is_available():
            try:
                result = self.analyze_with_prompt(
                    system_prompt,
                    analysis_prompt,
                    **llm_kwargs
                )

                if result:
                    # é©—è­‰é•·åº¦
                    actual_length = len(result.replace(' ', '').replace('\n', ''))
                    if actual_length >= min_length:
                        logger.info(f"âœ… LLMåˆ†ææˆåŠŸ ({actual_length}å­—)")
                        return result
                    else:
                        logger.warning(
                            f"âš ï¸ LLMè¼¸å‡º{actual_length}å­—ï¼Œæœªé”{min_length}å­—æ¨™æº–ï¼Œä½¿ç”¨fallback"
                        )
            except Exception as e:
                logger.error(f"âŒ LLMåˆ†æç•°å¸¸: {e}ï¼Œä½¿ç”¨fallback")
        else:
            logger.info("â„¹ï¸ LLMä¸å¯ç”¨ï¼Œä½¿ç”¨å‚³çµ±åˆ†ææ–¹æ³•")

        # Fallbackåˆ°å‚³çµ±æ–¹æ³•
        logger.info("ğŸ”„ åŸ·è¡Œfallbackåˆ†æ...")
        return fallback_func(*fallback_args)


# å…¨å±€LLMåˆ†æå™¨å¯¦ä¾‹ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰
_global_analyzer: Optional[LLMAnalyzer] = None


def get_llm_analyzer(
    force_reload: bool = False,
    provider: Optional[LLMProvider] = None
) -> LLMAnalyzer:
    """
    ç²å–å…¨å±€LLMåˆ†æå™¨å¯¦ä¾‹

    Args:
        force_reload: å¼·åˆ¶é‡æ–°åŠ è¼‰
        provider: æŒ‡å®šæä¾›å•†ï¼ˆåƒ…åœ¨é¦–æ¬¡åˆå§‹åŒ–æˆ–force_reloadæ™‚æœ‰æ•ˆï¼‰

    Returns:
        LLMåˆ†æå™¨å¯¦ä¾‹
    """
    global _global_analyzer

    if _global_analyzer is None or force_reload:
        # è‡ªå‹•æª¢æ¸¬å¯ç”¨çš„LLMæä¾›å•†
        if provider is None:
            # å„ªå…ˆä½¿ç”¨Claude Codeï¼ˆç„¡éœ€APIå¯†é‘°ï¼‰
            try:
                result = subprocess.run(
                    ["claude", "--version"],
                    capture_output=True,
                    text=True,
                    timeout=5
                )
                if result.returncode == 0:
                    provider = LLMProvider.CLAUDE_CODE
                    logger.info("æª¢æ¸¬åˆ°Claude Codeï¼Œä½¿ç”¨Claude Codeä½œç‚ºLLMæä¾›å•†")
                else:
                    raise FileNotFoundError("claude command not working")
            except (FileNotFoundError, subprocess.TimeoutExpired):
                # Claude Codeä¸å¯ç”¨ï¼Œæª¢æŸ¥å…¶ä»–æä¾›å•†
                if os.getenv('OPENAI_API_KEY'):
                    provider = LLMProvider.OPENAI
                    logger.info("æª¢æ¸¬åˆ°OPENAI_API_KEYï¼Œä½¿ç”¨OpenAI")
                elif os.getenv('ANTHROPIC_API_KEY'):
                    provider = LLMProvider.ANTHROPIC
                    logger.info("æª¢æ¸¬åˆ°ANTHROPIC_API_KEYï¼Œä½¿ç”¨Anthropic")
                else:
                    provider = LLMProvider.NONE
                    logger.info("æœªæª¢æ¸¬åˆ°LLMæä¾›å•†ï¼Œä½¿ç”¨å‚³çµ±åˆ†ææ–¹æ³•")

        _global_analyzer = LLMAnalyzer(provider=provider)

    return _global_analyzer


def construct_bazi_personality_prompt(bazi_data: Dict) -> str:
    """
    æ§‹å»ºå…«å­—æ€§æ ¼åˆ†ææç¤º

    Args:
        bazi_data: å…«å­—è¨ˆç®—æ•¸æ“š

    Returns:
        åˆ†ææç¤ºæ–‡æœ¬
    """
    return f"""
è«‹æ ¹æ“šä»¥ä¸‹å…«å­—å‘½ç›¤æ•¸æ“šï¼Œé€²è¡Œæ·±åº¦çš„æ€§æ ¼åˆ†æï¼ˆâ‰¥300å­—ï¼‰ï¼š

## å››æŸ±è³‡æ–™
{json.dumps(bazi_data.get('four_pillars', {}), ensure_ascii=False, indent=2)}

## äº”è¡ŒåŠ›é‡
{json.dumps(bazi_data.get('five_elements', {}), ensure_ascii=False, indent=2)}

## æ—¥ä¸»åˆ†æ
{json.dumps(bazi_data.get('day_master', {}), ensure_ascii=False, indent=2)}

## åç¥é…ç½®
{json.dumps(bazi_data.get('ten_gods', {}), ensure_ascii=False, indent=2)}

è«‹åš´æ ¼æŒ‰ç…§ç³»çµ±æç¤ºè©ä¸­ã€Œæ€§æ ¼ç‰¹è³ªã€çš„åˆ†ææ¡†æ¶ï¼Œæä¾›ï¼š
1. **æ—¥ä¸»ç‰¹æ€§åˆ†æ**ï¼ˆæ ¹æ“šæ—¥ä¸»å¤©å¹²çš„æ ¸å¿ƒç‰¹è³ªï¼‰
2. **åç¥é…ç½®è§£è®€**ï¼ˆé€šéåç¥çµ„åˆçœ‹æ€§æ ¼å´é¢ï¼‰
3. **ç¥ç…å½±éŸ¿**ï¼ˆè€ƒæ…®é‡è¦ç¥ç…çš„ä½œç”¨ï¼‰
4. **äº”è¡Œåé —å½±éŸ¿**ï¼ˆåˆ†æäº”è¡Œç¼ºå¤±æˆ–éæ—ºçš„å¿ƒç†å½±éŸ¿ï¼‰
5. **å…·é«”è¡Œç‚ºæ¨¡å¼**ï¼ˆçµ¦å‡ºå…·é«”çš„è¡Œç‚ºè¡¨ç¾å’Œå¿ƒç†ç‰¹é»ï¼‰
6. **æ€§æ ¼æ”¹å–„å»ºè­°**ï¼ˆé‡å°æ€§çš„ä¿®æ­£å»ºè­°ï¼‰

è¼¸å‡ºæ ¼å¼ï¼šå°ˆæ¥­çš„Markdownæ ¼å¼ï¼Œæ¸…æ™°åˆ†å±¤ï¼Œâ‰¥300å­—ã€‚
"""


def construct_bazi_career_prompt(bazi_data: Dict) -> str:
    """æ§‹å»ºå…«å­—äº‹æ¥­åˆ†ææç¤º"""
    return f"""
è«‹æ ¹æ“šä»¥ä¸‹å…«å­—å‘½ç›¤æ•¸æ“šï¼Œé€²è¡Œæ·±åº¦çš„äº‹æ¥­ç™¼å±•åˆ†æï¼ˆâ‰¥300å­—ï¼‰ï¼š

## å››æŸ±è³‡æ–™
{json.dumps(bazi_data.get('four_pillars', {}), ensure_ascii=False, indent=2)}

## å®˜æ˜Ÿåˆ†æ
{json.dumps(bazi_data.get('career_stars', {}), ensure_ascii=False, indent=2)}

## å¤§é‹æµå¹´
{json.dumps(bazi_data.get('luck_pillars', {}), ensure_ascii=False, indent=2)}

è«‹æŒ‰ç…§ç³»çµ±æç¤ºè©ä¸­ã€Œäº‹æ¥­ç™¼å±•ã€çš„åˆ†ææ¡†æ¶ï¼Œæä¾›ï¼š
1. **é©åˆè¡Œæ¥­**ï¼ˆæ ¹æ“šäº”è¡Œå’Œæ ¼å±€æ¨è–¦ï¼‰
2. **ç™¼å±•æ¨¡å¼**ï¼ˆæ‰“å·¥/å‰µæ¥­/è‡ªç”±è·æ¥­ï¼‰
3. **æ¬ŠåŠ›åœ°ä½**ï¼ˆå®˜é‹å’Œé ˜å°èƒ½åŠ›ï¼‰
4. **è·æ¥­è½‰æŠ˜**ï¼ˆé—œéµçš„äº‹æ¥­è½‰æŠ˜æœŸï¼‰
5. **ç™¼å±•å»ºè­°**ï¼ˆå…·é«”çš„è·æ¥­è¦åŠƒï¼‰

è¼¸å‡ºæ ¼å¼ï¼šå°ˆæ¥­çš„Markdownæ ¼å¼ï¼Œâ‰¥300å­—ã€‚
"""


def construct_ziwei_palace_prompt(palace_name: str, palace_data: Dict) -> str:
    """æ§‹å»ºç´«å¾®å®®ä½åˆ†ææç¤º"""
    min_chars = 250 if palace_name in ['å‘½å®®', 'å®˜ç¥¿å®®', 'è²¡å¸›å®®', 'å¤«å¦»å®®', 'ç¦å¾·å®®'] else 150

    return f"""
è«‹æ·±åº¦åˆ†æç´«å¾®æ–—æ•¸ã€{palace_name}ã€‘ï¼ˆâ‰¥{min_chars}å­—ï¼‰ï¼š

## å®®ä½è³‡æ–™
{json.dumps(palace_data, ensure_ascii=False, indent=2)}

è«‹æŒ‰ç…§ç³»çµ±æç¤ºè©ä¸­çš„åˆ†ææ¡†æ¶æä¾›ï¼š
1. **ä¸»æ˜Ÿç‰¹è³ª**ï¼ˆè©³ç´°è§£è®€ä¸»æ˜Ÿç‰¹æ€§ï¼‰
2. **è¼”ç…å½±éŸ¿**ï¼ˆå…­å‰å…­ç…çš„ä½œç”¨ï¼‰
3. **å››åŒ–æ•ˆæ‡‰**ï¼ˆå››åŒ–å°è©²å®®çš„å½±éŸ¿ï¼‰
4. **ä¸‰æ–¹å››æ­£**ï¼ˆç¶œåˆå…¶ä»–ç›¸é—œå®®ä½ï¼‰
5. **å…·é«”å»ºè­°**ï¼ˆå¯¦ç”¨çš„æŒ‡å¼•ï¼‰
6. **ä¿¡å¿ƒåº¦è©•ä¼°**ï¼ˆæ¨™è¨»åˆ†æçš„å¯é ç¨‹åº¦ï¼‰

è¼¸å‡ºæ ¼å¼ï¼šå°ˆæ¥­çš„Markdownæ ¼å¼ï¼Œâ‰¥{min_chars}å­—ã€‚
"""


def construct_astrology_area_prompt(area_name: str, astro_data: Dict) -> str:
    """æ§‹å»ºå æ˜Ÿé ˜åŸŸåˆ†ææç¤º"""
    return f"""
è«‹é€²è¡Œã€{area_name}ã€‘çš„å¿ƒç†å æ˜Ÿæ·±åº¦åˆ†æï¼ˆâ‰¥300å­—ï¼‰ï¼š

## æ˜Ÿç›¤è³‡æ–™
{json.dumps(astro_data, ensure_ascii=False, indent=2)}

è«‹æŒ‰ç…§ç³»çµ±æç¤ºè©æä¾›ï¼š
1. **è¡Œæ˜Ÿ/ä¸Šå‡é»çš„æ˜Ÿåº§ç‰¹è³ª**
2. **å®®ä½ä½ç½®çš„æ„ç¾©**
3. **ä¸»è¦ç›¸ä½çš„å¿ƒç†å‹•åŠ›**
4. **ç™¼å±•èª²é¡Œå’Œæˆé•·æ–¹å‘**
5. **æ•´åˆå»ºè­°**ï¼ˆä½¿ç”¨è³¦èƒ½å¼èªè¨€ï¼‰

è¼¸å‡ºæ ¼å¼ï¼šå°ˆæ¥­çš„Markdownæ ¼å¼ï¼Œä½¿ç”¨å¿ƒç†å­¸è¡“èªï¼Œâ‰¥300å­—ã€‚
"""


def construct_synthesis_prompt(
    domain_name: str,
    bazi_data: Dict,
    ziwei_data: Dict,
    astro_data: Dict
) -> str:
    """æ§‹å»ºä¸‰æ–¹æ³•ç¶œåˆåˆ†ææç¤º"""
    return f"""
è«‹é€²è¡Œã€{domain_name}ã€‘çš„ä¸‰æ–¹æ³•ç¶œåˆåˆ†æï¼ˆâ‰¥400å­—ï¼‰ï¼š

## å…«å­—æ•¸æ“š
{json.dumps(bazi_data, ensure_ascii=False, indent=2)}

## ç´«å¾®æ•¸æ“š
{json.dumps(ziwei_data, ensure_ascii=False, indent=2)}

## å æ˜Ÿæ•¸æ“š
{json.dumps(astro_data, ensure_ascii=False, indent=2)}

è«‹æŒ‰ç…§ç³»çµ±æç¤ºè©æä¾›ï¼š
1. **è­˜åˆ¥å…±æŒ¯é»**ï¼ˆä¸‰æ–¹ä¸€è‡´çš„ç‰¹è³ªï¼Œé€™äº›æ˜¯ä¿¡å¿ƒåº¦æœ€é«˜çš„çµè«–ï¼‰
2. **è·¨æ–¹æ³•æ•´åˆæ´å¯Ÿ**ï¼ˆå¾ä¸åŒè§’åº¦ç†è§£åŒä¸€ç‰¹è³ªï¼‰
3. **ä¿¡å¿ƒåº¦è©•ä¼°**ï¼ˆæ¥µé«˜/é«˜/ä¸­ç­‰ï¼ŒåŸºæ–¼æ–¹æ³•ä¸€è‡´æ€§ï¼‰
4. **æ•´åˆå»ºè­°**ï¼ˆç¶œåˆä¸‰æ–¹çš„å¯¦ç”¨å»ºè­°ï¼‰
5. **çŸ›ç›¾é»èªªæ˜**ï¼ˆå¦‚æœ‰ä¸ä¸€è‡´ï¼Œèª å¯¦èªªæ˜ï¼‰

è¼¸å‡ºæ ¼å¼ï¼šæŒ‰ç…§ç³»çµ±æç¤ºè©ä¸­çš„Markdownæ¨¡æ¿ï¼Œâ‰¥400å­—ã€‚
"""
